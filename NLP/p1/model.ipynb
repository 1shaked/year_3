{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load GloVe Embeddings\n",
    "def load_glove_embeddings(file_path, embedding_dim):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from the file into a dictionary.\n",
    "    \"\"\"\n",
    "    embedding_dict = {}\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]  # The word\n",
    "            vector = np.array(values[1:], dtype=\"float32\")  # The embedding vector\n",
    "            embedding_dict[word] = vector\n",
    "    print(f\"Loaded {len(embedding_dict)} word vectors.\")\n",
    "    return embedding_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the Embedding Matrix\n",
    "def create_embedding_matrix(vocab, glove_embeddings, embedding_dim):\n",
    "    \"\"\"\n",
    "    Create an embedding matrix where each row corresponds to a token in the vocabulary.\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))  # Initialize matrix with zeros\n",
    "\n",
    "    for word, idx in vocab.items():\n",
    "        if word in glove_embeddings:\n",
    "            embedding_matrix[idx] = glove_embeddings[word]\n",
    "        else:\n",
    "            # Initialize randomly for missing words\n",
    "            embedding_matrix[idx] = np.random.uniform(-0.01, 0.01, embedding_dim)\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GloVe file and embedding dimensions\n",
    "glove_file_path = \"glove.6B.100d.txt\"\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build Vocabulary\n",
    "# Example tokenized dataset (replace with your dataset tokens)\n",
    "vocab_file = 'imdb.vocab'\n",
    "with open(vocab_file, 'r') as f:\n",
    "    vocab_words = f.read().splitlines()\n",
    "\n",
    "tokenized_sentences = vocab_words\n",
    "tokenized_sentences.append('<UNK>')  # Add <UNK> token for unknown words\n",
    "tokenized_sentences.append('<PAD>')  # Add <PAD> token to pad sequences\n",
    "# Create vocabulary\n",
    "vocab_size = len(vocab_words)\n",
    "# tokens = list(chain(*tokenized_sentences))\n",
    "vocab_counter = Counter(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 89529\n"
     ]
    }
   ],
   "source": [
    "# Assign an index to each word in the vocabulary\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(vocab_counter.most_common())}\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (89529, 100)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix\n",
    "embedding_matrix = create_embedding_matrix(vocab, glove_embeddings, embedding_dim)\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -1.4590e-01,\n",
       "          8.2780e-01,  2.7062e-01],\n",
       "        [-7.1953e-02,  2.3127e-01,  2.3731e-02,  ..., -7.1895e-01,\n",
       "          8.6894e-01,  1.9539e-01],\n",
       "        [-2.7086e-01,  4.4006e-02, -2.0260e-02,  ..., -4.9230e-01,\n",
       "          6.3687e-01,  2.3642e-01],\n",
       "        ...,\n",
       "        [ 8.9225e-03, -7.5127e-03,  3.3671e-03,  ..., -8.5873e-03,\n",
       "         -2.2376e-03, -7.4692e-03],\n",
       "        [ 5.6891e-03,  1.4857e-03, -3.0688e-03,  ...,  5.3542e-03,\n",
       "         -8.7294e-04,  7.9123e-04],\n",
       "        [ 1.5660e-03, -7.9837e-03, -4.0311e-03,  ..., -4.8636e-03,\n",
       "          7.7952e-03,  8.9897e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Load Embedding Matrix into PyTorch Embedding Layer\n",
    "embedding_tensor = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding_layer = nn.Embedding(len(vocab), embedding_dim)\n",
    "embedding_layer.weight.data.copy_(embedding_tensor)  # Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer is ready.\n"
     ]
    }
   ],
   "source": [
    "# Optionally freeze the embedding layer\n",
    "embedding_layer.weight.requires_grad = False\n",
    "print(\"Embedding layer is ready.\")\n",
    "\n",
    "# Step 5: Test the Embedding Layer\n",
    "example_sentence = [\"this\", \"movie\", \"is\", \"great\"]  # Example input sentence\n",
    "token_indices = [vocab.get(token, vocab[\"<UNK>\"]) for token in example_sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input indices: [9, 15, 5, 83]\n",
      "Output embeddings shape: torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Convert token indices to a PyTorch tensor\n",
    "input_tensor = torch.tensor(token_indices).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Pass through the embedding layer\n",
    "output_embeddings = embedding_layer(input_tensor)\n",
    "print(f\"Input indices: {token_indices}\")\n",
    "print(f\"Output embeddings shape: {output_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output embeddings for the example sentence:\n",
      "torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Output embedding for visualization\n",
    "print(\"Output embeddings for the example sentence:\")\n",
    "print(output_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix=None, freeze_embeddings=True):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        \n",
    "        # Step 1. Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))  # Load pre-trained embeddings\n",
    "            self.embedding.weight.requires_grad = not freeze_embeddings  # Freeze or allow fine-tuning\n",
    "        \n",
    "        # Step 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Step 3. Fully Connected Layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Step 4. Sigmoid Activation for Binary Classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Pass embeddings through the LSTM layer\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        # Take the output from the last hidden state\n",
    "        final_output = self.fc(hidden[-1])\n",
    "        \n",
    "        # Apply sigmoid activation\n",
    "        output = self.sigmoid(final_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100  # Same as GloVe\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5  # Number of epochs\n",
    "\n",
    "# Initialize the LSTM model\n",
    "model = SentimentLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix, freeze_embeddings=True)\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_comments = []\n",
    "pos = os.listdir('train/pos')\n",
    "neg = os.listdir('train/neg')\n",
    "pos = list(filter(lambda x: '._' not in x, pos))\n",
    "neg = list(filter(lambda x: '._' not in x, neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18750"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for comments, labels in batched_comments:  # Assuming batched_comments is a DataLoader\n",
    "        # Move data to device\n",
    "        comments = comments.to(device)  # Shape: [batch_size, sequence_length]\n",
    "        labels = labels.to(device)  # Shape: [batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(comments).squeeze(1)  # Shape: [batch_size]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        # Accumulate loss for the epoch\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(batched_comments)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
