{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load GloVe Embeddings\n",
    "def load_glove_embeddings(file_path, embedding_dim):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from the file into a dictionary.\n",
    "    \"\"\"\n",
    "    embedding_dict = {}\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]  # The word\n",
    "            vector = np.array(values[1:], dtype=\"float32\")  # The embedding vector\n",
    "            embedding_dict[word] = vector\n",
    "    print(f\"Loaded {len(embedding_dict)} word vectors.\")\n",
    "    return embedding_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the Embedding Matrix\n",
    "def create_embedding_matrix(vocab, glove_embeddings, embedding_dim):\n",
    "    \"\"\"\n",
    "    Create an embedding matrix where each row corresponds to a token in the vocabulary.\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))  # Initialize matrix with zeros\n",
    "\n",
    "    for word, idx in vocab.items():\n",
    "        if word in glove_embeddings:\n",
    "            embedding_matrix[idx] = glove_embeddings[word]\n",
    "        else:\n",
    "            # Initialize randomly for missing words\n",
    "            embedding_matrix[idx] = np.random.uniform(-0.01, 0.01, embedding_dim)\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GloVe file and embedding dimensions\n",
    "glove_file_path = \"glove.6B.100d.txt\"\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build Vocabulary\n",
    "# Example tokenized dataset (replace with your dataset tokens)\n",
    "vocab_file = 'imdb.vocab'\n",
    "with open(vocab_file, 'r') as f:\n",
    "    vocab_words = f.read().splitlines()\n",
    "\n",
    "vocab_size = len(vocab_words)\n",
    "tokenized_sentences = vocab_words\n",
    "# Create vocabulary\n",
    "# tokens = list(chain(*tokenized_sentences))\n",
    "vocab_counter = Counter(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 89529\n"
     ]
    }
   ],
   "source": [
    "# Assign an index to each word in the vocabulary\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(vocab_counter.most_common())}\n",
    "vocab[\"<PAD>\"] = 0  # Add special token for padding\n",
    "vocab[\"<UNK>\"] = len(vocab)  # Add special token for unknown words\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (89529, 100)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix\n",
    "embedding_matrix = create_embedding_matrix(vocab, glove_embeddings, embedding_dim)\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.5091e-03, -4.2487e-03,  1.6969e-03,  ..., -9.4443e-03,\n",
       "          1.5800e-03,  1.9134e-03],\n",
       "        [-7.1953e-02,  2.3127e-01,  2.3731e-02,  ..., -7.1895e-01,\n",
       "          8.6894e-01,  1.9539e-01],\n",
       "        [-2.7086e-01,  4.4006e-02, -2.0260e-02,  ..., -4.9230e-01,\n",
       "          6.3687e-01,  2.3642e-01],\n",
       "        ...,\n",
       "        [-4.3755e-03,  5.8909e-03, -1.3712e-03,  ...,  3.8811e-03,\n",
       "         -6.1648e-04,  2.6436e-03],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-6.4111e-03, -9.2641e-03,  9.5760e-03,  ..., -6.4316e-03,\n",
       "          4.8961e-03, -1.9350e-03]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Load Embedding Matrix into PyTorch Embedding Layer\n",
    "embedding_tensor = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding_layer = nn.Embedding(len(vocab), embedding_dim)\n",
    "embedding_layer.weight.data.copy_(embedding_tensor)  # Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer is ready.\n"
     ]
    }
   ],
   "source": [
    "# Optionally freeze the embedding layer\n",
    "embedding_layer.weight.requires_grad = False\n",
    "print(\"Embedding layer is ready.\")\n",
    "\n",
    "# Step 5: Test the Embedding Layer\n",
    "example_sentence = [\"this\", \"movie\", \"is\", \"great\"]  # Example input sentence\n",
    "token_indices = [vocab.get(token, vocab[\"<UNK>\"]) for token in example_sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input indices: [9, 15, 5, 83]\n",
      "Output embeddings shape: torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Convert token indices to a PyTorch tensor\n",
    "input_tensor = torch.tensor(token_indices).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Pass through the embedding layer\n",
    "output_embeddings = embedding_layer(input_tensor)\n",
    "print(f\"Input indices: {token_indices}\")\n",
    "print(f\"Output embeddings shape: {output_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output embeddings for the example sentence:\n",
      "torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Output embedding for visualization\n",
    "print(\"Output embeddings for the example sentence:\")\n",
    "print(output_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89529, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([89529, 100])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 15, 5, 83]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Counter(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89527"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
