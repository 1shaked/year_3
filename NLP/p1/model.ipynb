{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load GloVe Embeddings\n",
    "def load_glove_embeddings(file_path, embedding_dim):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings from the file into a dictionary.\n",
    "    \"\"\"\n",
    "    embedding_dict = {}\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]  # The word\n",
    "            vector = np.array(values[1:], dtype=\"float32\")  # The embedding vector\n",
    "            embedding_dict[word] = vector\n",
    "    print(f\"Loaded {len(embedding_dict)} word vectors.\")\n",
    "    return embedding_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize comments\n",
    "def tokenize_comments(comments, vocab):\n",
    "    tokenized_comments = []\n",
    "    for comment in comments:\n",
    "        tokens = comment.split()  # Simple whitespace tokenizer\n",
    "        token_indices = [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]\n",
    "        tokenized_comments.append(token_indices)\n",
    "    return tokenized_comments\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "def pad_sequences(sequences, max_len, pad_value):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_len:\n",
    "            seq = seq + [pad_value] * (max_len - len(seq))\n",
    "        else:\n",
    "            seq = seq[:max_len]\n",
    "        padded_sequences.append(seq)\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create the Embedding Matrix\n",
    "def create_embedding_matrix(vocab, glove_embeddings, embedding_dim):\n",
    "    \"\"\"\n",
    "    Create an embedding matrix where each row corresponds to a token in the vocabulary.\n",
    "    \"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))  # Initialize matrix with zeros\n",
    "\n",
    "    for word, idx in vocab.items():\n",
    "        if word in glove_embeddings:\n",
    "            embedding_matrix[idx] = glove_embeddings[word]\n",
    "        else:\n",
    "            # Initialize randomly for missing words\n",
    "            embedding_matrix[idx] = np.random.uniform(-0.01, 0.01, embedding_dim)\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to GloVe file and embedding dimensions\n",
    "glove_file_path = \"glove.6B.100d.txt\"\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build Vocabulary\n",
    "# Example tokenized dataset (replace with your dataset tokens)\n",
    "vocab_file = 'imdb.vocab'\n",
    "with open(vocab_file, 'r') as f:\n",
    "    vocab_words = f.read().splitlines()\n",
    "\n",
    "tokenized_sentences = vocab_words\n",
    "tokenized_sentences.append('<UNK>')  # Add <UNK> token for unknown words\n",
    "tokenized_sentences.append('<PAD>')  # Add <PAD> token to pad sequences\n",
    "# Create vocabulary\n",
    "vocab_size = len(vocab_words)\n",
    "# tokens = list(chain(*tokenized_sentences))\n",
    "vocab_counter = Counter(tokenized_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 89529\n"
     ]
    }
   ],
   "source": [
    "# Assign an index to each word in the vocabulary\n",
    "vocab = {word: idx for idx, (word, _) in enumerate(vocab_counter.most_common())}\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (89529, 100)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix\n",
    "embedding_matrix = create_embedding_matrix(vocab, glove_embeddings, embedding_dim)\n",
    "print(f\"Embedding matrix shape: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -1.4590e-01,\n",
       "          8.2780e-01,  2.7062e-01],\n",
       "        [-7.1953e-02,  2.3127e-01,  2.3731e-02,  ..., -7.1895e-01,\n",
       "          8.6894e-01,  1.9539e-01],\n",
       "        [-2.7086e-01,  4.4006e-02, -2.0260e-02,  ..., -4.9230e-01,\n",
       "          6.3687e-01,  2.3642e-01],\n",
       "        ...,\n",
       "        [ 8.9225e-03, -7.5127e-03,  3.3671e-03,  ..., -8.5873e-03,\n",
       "         -2.2376e-03, -7.4692e-03],\n",
       "        [ 5.6891e-03,  1.4857e-03, -3.0688e-03,  ...,  5.3542e-03,\n",
       "         -8.7294e-04,  7.9123e-04],\n",
       "        [ 1.5660e-03, -7.9837e-03, -4.0311e-03,  ..., -4.8636e-03,\n",
       "          7.7952e-03,  8.9897e-03]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Load Embedding Matrix into PyTorch Embedding Layer\n",
    "embedding_tensor = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding_layer = nn.Embedding(len(vocab), embedding_dim)\n",
    "embedding_layer.weight.data.copy_(embedding_tensor)  # Load pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer is ready.\n"
     ]
    }
   ],
   "source": [
    "# Optionally freeze the embedding layer\n",
    "embedding_layer.weight.requires_grad = False\n",
    "print(\"Embedding layer is ready.\")\n",
    "\n",
    "# Step 5: Test the Embedding Layer\n",
    "example_sentence = [\"this\", \"movie\", \"is\", \"great\"]  # Example input sentence\n",
    "token_indices = [vocab.get(token, vocab[\"<UNK>\"]) for token in example_sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input indices: [9, 15, 5, 83]\n",
      "Output embeddings shape: torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "# Convert token indices to a PyTorch tensor\n",
    "input_tensor = torch.tensor(token_indices).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Pass through the embedding layer\n",
    "output_embeddings = embedding_layer(input_tensor)\n",
    "print(f\"Input indices: {token_indices}\")\n",
    "print(f\"Output embeddings shape: {output_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output embeddings for the example sentence:\n",
      "torch.Size([1, 4, 100])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Output embedding for visualization\n",
    "print(\"Output embeddings for the example sentence:\")\n",
    "print(output_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix=None, freeze_embeddings=True):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        \n",
    "        # Step 1. Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))  # Load pre-trained embeddings\n",
    "            self.embedding.weight.requires_grad = not freeze_embeddings  # Freeze or allow fine-tuning\n",
    "        \n",
    "        # Step 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        \n",
    "        # Step 3. Fully Connected Layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Step 4. Sigmoid Activation for Binary Classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Pass embeddings through the LSTM layer\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        # Take the output from the last hidden state\n",
    "        final_output = self.fc(hidden[-1])\n",
    "        \n",
    "        # Apply sigmoid activation\n",
    "        output = self.sigmoid(final_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100  # Same as GloVe\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5  # Number of epochs\n",
    "\n",
    "# Initialize the LSTM model\n",
    "model = SentimentLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, embedding_matrix, freeze_embeddings=True)\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_comments = []\n",
    "pos = os.listdir('train/pos')\n",
    "neg = os.listdir('train/neg')\n",
    "pos = list(filter(lambda x: '._' not in x, pos))\n",
    "neg = list(filter(lambda x: '._' not in x, neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the comments from files\n",
    "pos_comments = [open(f'train/pos/{f}', 'r').read() for f in pos]\n",
    "neg_comments = [open(f'train/neg/{f}', 'r').read() for f in neg]\n",
    "\n",
    "# Label the comments\n",
    "pos_labels = [1] * len(pos_comments)\n",
    "neg_labels = [0] * len(neg_comments)\n",
    "\n",
    "# Combine and shuffle the comments and labels\n",
    "comments = pos_comments + neg_comments\n",
    "labels = pos_labels + neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = list(zip(comments, labels))\n",
    "random.shuffle(combined)\n",
    "comments, labels = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create batches of size 50\n",
    "batch_size = 50\n",
    "batched_comments = [(comments[i:i + batch_size], labels[i:i + batch_size]) for i in range(0, len(comments), batch_size)]\n",
    "len(batched_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "test_size = 0.2\n",
    "train_len = train_size * len(batched_comments)\n",
    "test_len = len(batched_comments) - train_len\n",
    "train_comments = batched_comments[:int(train_len)]\n",
    "val_comments = labels[:int(train_len)]\n",
    "\n",
    "test_comments = batched_comments[int(train_len):]\n",
    "test_labels = labels[int(train_len):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comments, labels \u001b[38;5;129;01min\u001b[39;00m train_comments:  \u001b[38;5;66;03m# Assuming train_comments is a list of (comments, labels) batches\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Move data to device\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     comments_padded \u001b[38;5;241m=\u001b[39m pad_sequences(tokenize_comments(comments, vocab), max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, pad_value\u001b[38;5;241m=\u001b[39mvocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m     comments_tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomments_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     comments \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(comments_tokenized, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Shape: [batch_size, sequence_length]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Shape: [batch_size]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[54], line 5\u001b[0m, in \u001b[0;36mtokenize_comments\u001b[0;34m(comments, vocab)\u001b[0m\n\u001b[1;32m      3\u001b[0m tokenized_comments \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m comments:\n\u001b[0;32m----> 5\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mcomment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()  \u001b[38;5;66;03m# Simple whitespace tokenizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     token_indices \u001b[38;5;241m=\u001b[39m [vocab\u001b[38;5;241m.\u001b[39mget(token, vocab[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<UNK>\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens]\n\u001b[1;32m      7\u001b[0m     tokenized_comments\u001b[38;5;241m.\u001b[39mappend(token_indices)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Loop through batches\n",
    "    for comments, labels in train_comments:  # Assuming train_comments is a list of (comments, labels) batches\n",
    "        # Move data to device\n",
    "        comments_padded = pad_sequences(tokenize_comments(comments, vocab), max_len=200, pad_value=vocab[\"<PAD>\"])\n",
    "        comments_tokenized = tokenize_comments(comments_padded, vocab)\n",
    "        \n",
    "        comments = torch.tensor(comments_tokenized, dtype=torch.long).to(device)  # Shape: [batch_size, sequence_length]\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Shape: [batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(comments).squeeze(1)  # Shape: [batch_size]\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model weights\n",
    "\n",
    "        # Accumulate loss and accuracy\n",
    "        epoch_loss += loss.item()\n",
    "        preds = (predictions >= 0.5).float()  # Convert probabilities to binary labels\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "    # Print epoch summary\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(train_comments):.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I do not like Himesh Reshamiya. I do not like his singing too. But his songs are a craze in India, especially among commoners. Now when he ventured to become an actor \\x96 that was a big joke! What guts he has to reap as much as he can in his prime time. I did never want to see this movie. But one thing changed it. The movie becoming a super-duper hit! After 2 weeks, Aap Ka Saroor has raked box office collection of 14 crores \\x96 compared to Apne that has collected 7 crores in the same 2 weeks. If I can sit through Apne and Rajnikant's absurd Sivaji \\x96 I should give this movie also a try to understand what stuff this movie has got that made it such a big hit? The story is about the real life singer Himesh Reshamiya (HR) who has gone to Germany for a concert and falls in love with Riya (Hansika Motwani). A German lawyer Ruby (Mallika Sherawat) loves Himesh. Now Himesh is arrested for a murder. The mission of Himesh (in last 40 minutes) after he runs away from jail is to prove himself innocent and find the real murderer.<br /><br />Let me say that Himesh has nothing in him to become a hero. He tries hard but fails miserably. He is pathetic. I was thinking what could have made the movie click so much? Let me find something positive.<br /><br />First, the saving grace of the movie is the script till the point Himesh runs away from the jail. (But after that the movie nose dives into unbearable stupid limits) Second, the songs of the movie are good, catchy, crowd puller numbers. Third, Mallika Sherawat \\x96 she looks gorgeous and acts well too, as the second lady. I can imagine fans of Mallika coming to see the movie just for her. Fourth, the cinematography of the movie is pleasing \\x96 especially the German locales, are a treat to watch for the eye. Fifth, the major portion of the story is a love story between Himesh and Riya \\x96 with clichéd dialogues that would probably connect to young crowd. Sixth, the Director Prashant Chadha has done a decent job in covering the pathetic acting skills of Himesh as much as possible with shots that don't need Himesh to act much.<br /><br />The heroine Hansika Motwani looks like a small budget film heroine. Raj Babbar is wasted in a small role. Overall the movie is a below average.<br /><br />I was thinking throughout the movie \\x96 what if the same movie script was done with Salmaan as the main lead. I think it would have had been a much better affair. May be then I would have given the movie 6 out of 10. But now\\x85 (Stars 4.5 out of 10)\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tokenize_comments(comments, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89527"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
